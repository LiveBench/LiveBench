# OpenAI Models
---
display_name: gpt-4o-2024-11-20
api_name:
  openai: gpt-4o-2024-11-20
aliases:
  - gpt-4o
---
display_name: chatgpt-4o-latest-2025-03-27
api_name:
  openai: chatgpt-4o-latest
aliases:
  - chatgpt-4o-latest
agent_config:
  default:
    supports_function_calling: false
---
display_name: gpt-3.5-turbo
api_name:
  openai: gpt-3.5-turbo
---
display_name: gpt-3.5-turbo-1106
api_name:
  openai: gpt-3.5-turbo-1106
---
display_name: gpt-3.5-turbo-0125
api_name:
  openai: gpt-3.5-turbo-0125
---
display_name: gpt-4
api_name:
  openai: gpt-4
---
display_name: gpt-4-0314
api_name:
  openai: gpt-4-0314
---
display_name: gpt-4-0613
api_name:
  openai: gpt-4-0613
---
display_name: gpt-4-turbo
api_name:
  openai: gpt-4-turbo
---
display_name: gpt-4-turbo-2024-04-09
api_name:
  openai: gpt-4-turbo-2024-04-09
---
display_name: gpt-4-1106-preview
api_name:
  openai: gpt-4-1106-preview
---
display_name: gpt-4-0125-preview
api_name:
  openai: gpt-4-0125-preview
---
display_name: gpt-4o-2024-05-13
api_name:
  openai: gpt-4o-2024-05-13
---
display_name: gpt-4o-mini-2024-07-18
api_name:
  openai: gpt-4o-mini-2024-07-18
aliases:
  - gpt-4o-mini
---
display_name: gpt-4o-2024-08-06
api_name:
  openai: gpt-4o-2024-08-06
---
display_name: gpt-4.5-preview-2025-02-27
api_name:
  openai: gpt-4.5-preview-2025-02-27
aliases:
  - gpt-4.5-preview
---
display_name: gpt-5-minimal
api_name:
  openai: gpt-5
  openai_responses: gpt-5
default_provider: openai_responses
aliases:
  - gpt-5-minimal
api_kwargs:
  default:
    temperature: null
  openai:
    max_completion_tokens: null
    reasoning_effort: minimal
  openai_responses:
    max_output_tokens: null
    reasoning:
      effort: minimal
      summary: auto
agent_config:
  default:
    max_input_tokens: 300000
    max_output_tokens: 100000
    supports_function_calling: true
---
display_name: gpt-5-low
api_name:
  openai: gpt-5
  openai_responses: gpt-5
default_provider: openai_responses
aliases:
  - gpt-5-low
api_kwargs:
  default:
    temperature: null
  openai:
    max_completion_tokens: null
    reasoning_effort: low
  openai_responses:
    max_output_tokens: null
    reasoning:
      effort: low
      summary: auto
agent_config:
  default:
    max_input_tokens: 300000
    max_output_tokens: 100000
    supports_function_calling: true
---
display_name: gpt-5
api_name:
  openai: gpt-5
  openai_responses: gpt-5
default_provider: openai_responses
aliases:
  - gpt-5
api_kwargs:
  default:
    temperature: null
    max_completion_tokens: null
agent_config:
  default:
    max_input_tokens: 300000
    max_output_tokens: 100000
    supports_function_calling: true
---
display_name: gpt-5-high
api_name:
  openai: gpt-5
  openai_responses: gpt-5
default_provider: openai_responses
aliases:
  - gpt-5-high
api_kwargs:
  default:
    temperature: null
  openai:
    max_completion_tokens: null
    reasoning_effort: high
  openai_responses:
    max_output_tokens: null
    reasoning:
      effort: high
      summary: auto
agent_config:
  default:
    max_input_tokens: 390000
    max_output_tokens: 120000
    supports_function_calling: true
---
display_name: gpt-5-mini-low
api_name:
  openai: gpt-5-mini
  openai_responses: gpt-5-mini
default_provider: openai_responses
aliases:
  - gpt-5-mini-low
api_kwargs:
  default:
    temperature: null
  openai:
    max_completion_tokens: null
    reasoning_effort: low
  openai_responses:
    max_output_tokens: null
    reasoning:
      effort: low
      summary: auto
agent_config:
  default:
    max_input_tokens: 300000
    max_output_tokens: 100000
    supports_function_calling: true
---
display_name: gpt-5-chat
api_name:
  openai: gpt-5-chat-latest
  openai_responses: gpt-5-chat-latest
default_provider: openai_responses
aliases:
  - gpt-5-chat
api_kwargs:
  default:
    temperature: null
  openai:
    max_completion_tokens: null
  openai_responses:
    max_output_tokens: null
agent_config:
  default:
    max_input_tokens: 300000
    max_output_tokens: 100000
---
display_name: gpt-5-mini
api_name:
  openai: gpt-5-mini
  openai_responses: gpt-5-mini
default_provider: openai_responses
aliases:
  - gpt-5-mini
api_kwargs:
  default:
    temperature: null
    max_completion_tokens: null
agent_config:
  default:
    max_input_tokens: 390000
    max_output_tokens: 120000
    supports_function_calling: true
---
display_name: gpt-5-mini-high
api_name:
  openai: gpt-5-mini
  openai_responses: gpt-5-mini
default_provider: openai_responses
aliases:
  - gpt-5-mini-high
api_kwargs:
  default:
    temperature: null
  openai:
    max_completion_tokens: null
    reasoning_effort: high
  openai_responses:
    max_output_tokens: null
    reasoning:
      effort: high
      summary: auto
agent_config:
  default:
    max_input_tokens: 390000
    max_output_tokens: 120000
    supports_function_calling: true
---
display_name: gpt-5-nano-low
api_name:
  openai: gpt-5-nano
  openai_responses: gpt-5-nano
default_provider: openai_responses
aliases:
  - gpt-5-nano-low
api_kwargs:
  default:
    temperature: null
  openai:
    max_completion_tokens: null
    reasoning_effort: low
  openai_responses:
    max_output_tokens: null
    reasoning:
      effort: low
      summary: auto
agent_config:
  default:
    max_input_tokens: 390000
    max_output_tokens: 120000
    supports_function_calling: true
---
display_name: gpt-5-nano
api_name:
  openai: gpt-5-nano
  openai_responses: gpt-5-nano
default_provider: openai_responses
aliases:
  - gpt-5-nano
api_kwargs:
  default:
    temperature: null
    max_completion_tokens: null
agent_config:
  default:
    max_input_tokens: 390000
    max_output_tokens: 120000
    supports_function_calling: true
---
display_name: gpt-5-nano-high
api_name:
  openai: gpt-5-nano
  openai_responses: gpt-5-nano
default_provider: openai_responses
aliases:
  - gpt-5-nano-high
api_kwargs:
  default:
    temperature: null
  openai:
    max_completion_tokens: null
    reasoning_effort: high
  openai_responses:
    max_output_tokens: null
    reasoning:
      effort: high
      summary: auto
agent_config:
  default:
    max_input_tokens: 390000
    max_output_tokens: 120000
    supports_function_calling: true
---
display_name: o1-mini-2024-09-12
api_name:
  openai: o1-mini-2024-09-12
aliases:
  - o1-mini
api_kwargs:
  default:
    temperature: null
    max_completion_tokens: null
---
display_name: o1-preview-2024-09-12
api_name:
  openai: o1-preview-2024-09-12
aliases:
  - o1-preview
api_kwargs:
  default:
    temperature: null
    max_completion_tokens: null
---
display_name: o1-2024-12-17-high
api_name:
  openai: o1-2024-12-17
aliases:
  - o1
  - o1-high
  - o1-2024-12-17
api_kwargs:
  default:
    temperature: null
    max_completion_tokens: null
    reasoning_effort: high
prompt_prefix: "Formatting reenabled"
---
display_name: o1-2024-12-17-low
api_name:
  openai: o1-2024-12-17
aliases:
  - o1-low
api_kwargs:
  default:
    temperature: null
    max_completion_tokens: null
    reasoning_effort: low
prompt_prefix: "Formatting reenabled"
---
display_name: o1-2024-12-17-medium
api_name:
  openai: o1-2024-12-17
aliases:
  - o1-medium
api_kwargs:
  default:
    temperature: null
    max_completion_tokens: null
    reasoning_effort: medium
prompt_prefix: "Formatting reenabled"
---
display_name: o3-mini-2025-01-31-high
api_name:
  openai: o3-mini-2025-01-31
  openai_responses: o3-mini-2025-01-31
default_provider: openai_responses
aliases:
  - o3-mini-high
  - o3-mini
  - o3-mini-2025-01-31
api_kwargs:
  default:
    temperature: null
  openai:
    max_completion_tokens: null
    reasoning_effort: high
  openai_responses:
    max_output_tokens: null
    reasoning:
      effort: high
      summary: auto
prompt_prefix: "Formatting reenabled"
---
display_name: o3-mini-2025-01-31-low
api_name:
  openai: o3-mini-2025-01-31
  openai_responses: o3-mini-2025-01-31
default_provider: openai_responses
aliases:
  - o3-mini-low
api_kwargs:
  default:
    temperature: null
  openai:
    max_completion_tokens: null
    reasoning_effort: low
  openai_responses:
    max_output_tokens: null
    reasoning:
      effort: low
      summary: auto
prompt_prefix: "Formatting reenabled"
---
display_name: o3-mini-2025-01-31-medium
api_name:
  openai: o3-mini-2025-01-31
  openai_responses: o3-mini-2025-01-31
default_provider: openai_responses
aliases:
  - o3-mini-medium
api_kwargs:
  default:
    temperature: null
  openai:
    reasoning_effort: medium
    max_completion_tokens: null
  openai_responses:
    max_output_tokens: null
    reasoning:
      effort: medium
      summary: auto
prompt_prefix: "Formatting reenabled"
---
display_name: o1-pro-2025-03-19
api_name:
  openai_responses: o1-pro-2025-03-19
aliases:
  - o1-pro
api_kwargs:
  default:
    temperature: null
    max_output_tokens: null
    reasoning_effort: high
prompt_prefix: "Formatting reenabled"
---
display_name: gpt-4.1-2025-04-14
api_name:
  openai: gpt-4.1-2025-04-14
aliases:
  - gpt-4.1
---
display_name: gpt-4.1-mini-2025-04-14
api_name:
  openai: gpt-4.1-mini-2025-04-14
aliases:
  - gpt-4.1-mini
---
display_name: gpt-4.1-nano-2025-04-14
api_name:
  openai: gpt-4.1-nano-2025-04-14
aliases:
  - gpt-4.1-nano
---
display_name: o3-2025-04-16-high
api_name:
  openai: o3-2025-04-16
  openai_responses: o3-2025-04-16
default_provider: openai_responses
aliases:
  - o3-high
  - o3-2025-04-16-high
api_kwargs:
  default:
    temperature: null
  openai:
    max_completion_tokens: null
    reasoning_effort: high
  openai_responses:
    max_output_tokens: null
    reasoning:
      effort: high
      summary: auto
prompt_prefix: "Formatting reenabled"
---
display_name: o3-2025-04-16-medium
api_name:
  openai: o3-2025-04-16
  openai_responses: o3-2025-04-16
default_provider: openai_responses
aliases:
  - o3-medium
  - o3-2025-04-16-medium
api_kwargs:
  default:
    temperature: null
  openai:
    max_completion_tokens: null
    reasoning_effort: medium
  openai_responses:
    max_output_tokens: null
    reasoning:
      effort: medium
      summary: auto
prompt_prefix: "Formatting reenabled"
---
display_name: o4-mini-2025-04-16-high
api_name:
  openai: o4-mini-2025-04-16
  openai_responses: o4-mini-2025-04-16
default_provider: openai_responses
aliases:
  - o4-mini-high
api_kwargs:
  default:
    temperature: null
  openai:
    max_completion_tokens: null
    reasoning_effort: high
  openai_responses:
    max_output_tokens: null
    reasoning:
      effort: high
      summary: auto
prompt_prefix: "Formatting reenabled"
---
display_name: o4-mini-2025-04-16-medium
api_name:
  openai: o4-mini-2025-04-16
  openai_responses: o4-mini-2025-04-16
default_provider: openai_responses
aliases:
  - o4-mini-medium
api_kwargs:
  default:
    temperature: null
  openai:
    max_completion_tokens: null
    reasoning_effort: medium
  openai_responses:
    max_output_tokens: null
    reasoning:
      effort: medium
      summary: auto
prompt_prefix: "Formatting reenabled"
---
display_name: o3-pro-2025-06-10-medium
api_name:
  openai_responses: o3-pro-2025-06-10
default_provider: openai_responses
aliases:
  - o3-pro-medium
api_kwargs:
  default:
    max_output_tokens: null
    temperature: null
    reasoning:
      effort: medium
      summary: auto
prompt_prefix: "Formatting reenabled"
agent_config:
  default:
    max_input_tokens: 200000
    max_output_tokens: 100000
    supports_function_calling: true
---
display_name: o3-pro-2025-06-10-high
api_name:
  openai_responses: o3-pro-2025-06-10
default_provider: openai_responses
aliases:
  - o3-pro-high
api_kwargs:
  default:
    max_output_tokens: null
    temperature: null
    reasoning:
      effort: high
      summary: auto
prompt_prefix: "Formatting reenabled"
agent_config:
  default:
    max_input_tokens: 200000
    max_output_tokens: 100000
    supports_function_calling: true
---
display_name: gpt-oss-120b
api_name:
  https://api.fireworks.ai/inference/v1: accounts/fireworks/models/gpt-oss-120b
api_keys:
  https://api.fireworks.ai/inference/v1: FW_API_KEY
api_kwargs:
  default:
    max_completion_tokens: 32766
    temperature: null
agent_config:
  default:
    max_input_tokens: 131072
    max_output_tokens: 32000
    supports_function_calling: true
