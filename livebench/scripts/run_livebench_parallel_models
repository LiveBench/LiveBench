#!/bin/bash
## Run the livebench benchmark in parallel using the specified models
## For each model, this script will run gen_api_answer and then gen_ground_truth_judgment for the specified benchmark subset.
## Each model is run in a separate tmux session
## The question-source argument is optional; if not provided, the questions will be downloaded from huggingface
## Usage: run_livebench_parallel_models <venv-path> <question-source>
## Example: run_livebench_parallel_models ../.venv/bin/activate jsonl

venv=$1
question_source=$2

if [ -z "$venv" ]; then
    echo "Usage: run_livebench_parallel_models <venv-path> <optional-question-source>"
    exit 1
fi

echo "Running livebench benchmarks in parallel using $venv"

MODELS=(
    # "gpt-4o-2024-11-20"
    # "gpt-4o-2024-08-06"
    # "gpt-4o-mini-2024-07-18"
    # "o1-mini-2024-09-12"
    # "o1-preview-2024-09-12"
    # "claude-3-5-sonnet-20241022"
    # "claude-3-5-haiku-20241022"
    "meta-llama-3.1-70b-instruct-turbo"
    "meta-llama-3.1-8b-instruct-turbo"
    "meta-llama-3.1-405b-instruct-turbo"
    # "gemini-exp-1121"
    # "gemini-1.5-flash-001"
    # "gemini-1.5-flash-002"
    # "claude-3-5-sonnet-20240620"
    # "gemini-exp-1114"
    # "gemini-1.5-pro-001"
    # "gemini-1.5-pro-002"
    # "gemini-1.5-pro-exp-0827"
    # "gpt-4-turbo-2024-04-09"
    # "claude-3-opus-20240229"
    # "gpt-4-0125-preview"
    # "mistral-large-2407"
    # "mistral-large-2411"
    # "gemini-1.5-flash-exp-0827"
    # "gemini-1.5-flash-8b-0827"
    "Qwen2.5-7B-Instruct-Turbo"
    "Qwen2.5-72B-Instruct-Turbo"
    # "claude-3-haiku-20240307"
    # "open-mixtral-8x22b"
    # "open-mistral-nemo"
    # "mistral-small-2402"
    # "mistral-small-2409"
    # "command-r-plus-08-2024"
    # "command-r-plus-04-2024"
    # "command-r-08-2024"
    # "command-r-03-2024"
    # "gemma-2-27b-it"
    # "gemma-2-9b-it"
)

# For each model
for model in "${MODELS[@]}"; do
    ./scripts/run_livebench_parallel $model $venv $question_source
done

echo "Benchmark tmux sessions:"
tmux ls